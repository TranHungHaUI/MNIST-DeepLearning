#Lớp giữ lại: 1 - selected_class
#Lớp còn lại: 0 - other_class
#Lấy 80% (hoặc khác) giảm kích thước lớp other 
#Mục đích để cân bằng số lượng 2 lớp (0/1)
#Giảm bằng cách lấy ngẫu nhiên 80% trong các lớp
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from sklearn.utils.class_weight import compute_class_weight

# Tải dữ liệu MNIST
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Lựa chọn lớp bạn muốn giữ lại, ví dụ, số '1'
selected_class = 1

# Tạo nhãn mới: 1 cho lớp được giữ lại, 0 cho các lớp còn lại
train_labels_new = (train_labels == selected_class).astype(int)
test_labels_new = (test_labels == selected_class).astype(int)

# Tách dữ liệu theo lớp
class_selected_images = train_images[train_labels == selected_class]
class_selected_labels = train_labels_new[train_labels == selected_class]

class_other_images = train_images[train_labels != selected_class]
class_other_labels = train_labels_new[train_labels != selected_class]

# Lấy ngẫu nhiên 80% dữ liệu từ lớp "other"
random_indices = np.random.choice(class_other_images.shape[0], int(class_other_images.shape[0] * 0.9), replace=False)
class_other_images_reduced = class_other_images[random_indices]
class_other_labels_reduced = class_other_labels[random_indices]

# Kết hợp lại dữ liệu
train_images_reduced = np.concatenate((class_selected_images, class_other_images_reduced), axis=0)
train_labels_reduced = np.concatenate((class_selected_labels, class_other_labels_reduced), axis=0)

# Chuẩn hóa dữ liệu
train_images_reduced = train_images_reduced / 255.0
test_images = test_images / 255.0

# Tính trọng số lớp
class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_reduced), y=train_labels_reduced)
class_weights_dict = dict(enumerate(class_weights))
# Tăng trọng số của lớp thiểu số để tăng trọng số của lớp được giữ lại
# Điều chỉnh thủ công `class_weight` cho lớp thiểu số (1) và lớp đa số (0)
class_weights_dict[1] *= 1.5  # Tăng trọng số cho lớp thiểu số
class_weights_dict[0] *= 0.5  # Giảm trọng số cho lớp đa số

# Xây dựng mô hình
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dropout(0.5),  # Thêm Dropout để tránh overfitting
    Dense(128, activation='relu'),
    Dropout(0.5),  # Thêm Dropout
    Dense(1, activation='sigmoid')
])

# Biên dịch mô hình với learning rate thấp hơn để cải thiện hội tụ
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Huấn luyện mô hình với class_weight
model.fit(train_images_reduced, train_labels_reduced,
          epochs=30, batch_size=128,
          validation_data=(test_images, test_labels_new),
          class_weight=class_weights_dict)

# Đánh giá mô hình
test_loss, test_accuracy = model.evaluate(test_images, test_labels_new)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')