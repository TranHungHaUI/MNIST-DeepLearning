#Lấy dữ liệu ảnh số [0,...,9] từ thư viện ảnh MNIST
#Lớp được giữ lại: 1 - selected_class
#Các Lớp khác (other): 0 - other
#1. Lấy 20% dữ liệu mỗi phần trong lớp other
#2. Resize ảnh đầu vào để sử dụng mô hình VGG16
#3. Load mô hình VGG16 đã được pre-trained với trọng số từ ImageNet, không bao gồm top layer
#4. Đóng băng các lớp trong base model
#5. Thêm các lớp fully connected mới
#6. Tạo mô hình cuối cùng
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight

# Tải dữ liệu MNIST
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Lựa chọn lớp bạn muốn giữ lại, ví dụ, số '1'
selected_class = 1

# Tạo nhãn mới: 1 cho lớp được giữ lại, 0 cho các lớp còn lại
train_labels_new = (train_labels == selected_class).astype(int)
test_labels_new = (test_labels == selected_class).astype(int)

# Tách dữ liệu theo lớp
class_selected_images = train_images[train_labels == selected_class]
class_selected_labels = train_labels_new[train_labels == selected_class]

class_other_images = []
class_other_labels = []

for label in range(10):
    if label != selected_class:
        class_images = train_images[train_labels == label]
        class_labels = train_labels_new[train_labels == label]
        random_indices = np.random.choice(class_images.shape[0], int(class_images.shape[0] * 0.2), replace=False)
        class_other_images.append(class_images[random_indices])
        class_other_labels.append(class_labels[random_indices])

# Gộp dữ liệu từ các lớp khác thành lớp "other"
class_other_images_reduced = np.concatenate(class_other_images, axis=0)
class_other_labels_reduced = np.concatenate(class_other_labels, axis=0)

# Kết hợp lại dữ liệu
train_images_reduced = np.concatenate((class_selected_images, class_other_images_reduced), axis=0)
train_labels_reduced = np.concatenate((class_selected_labels, class_other_labels_reduced), axis=0)

# Chuẩn hóa dữ liệu
train_images_reduced = train_images_reduced / 255.0
test_images = test_images / 255.0

# Chuyển đổi dữ liệu thành định dạng cần thiết cho VGG16 (3 kênh) và thay đổi kích thước
train_images_reduced = np.stack([train_images_reduced] * 3, axis=-1)
test_images = np.stack([test_images] * 3, axis=-1)

train_images_resized = tf.image.resize(train_images_reduced, [32, 32])
test_images_resized = tf.image.resize(test_images, [32, 32])

# Tính trọng số lớp
class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_reduced), y=train_labels_reduced)
class_weights_dict = dict(enumerate(class_weights))

# Load mô hình VGG16 đã được pre-trained với trọng số từ ImageNet, không bao gồm top layer
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))

# Đóng băng các lớp trong base model
for layer in base_model.layers:
    layer.trainable = False

# Thêm các lớp fully connected mới
x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Tạo mô hình cuối cùng
model = Model(inputs=base_model.input, outputs=predictions)

# Biên dịch mô hình với learning rate thấp hơn để cải thiện hội tụ
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Huấn luyện mô hình với class_weight
model.fit(train_images_resized, train_labels_reduced, 
          epochs=20, batch_size=32, 
          validation_data=(test_images_resized, test_labels_new), 
          class_weight=class_weights_dict)

# Đánh giá mô hình
test_loss, test_accuracy = model.evaluate(test_images_resized, test_labels_new)
print(f'Test accuracy: {test_accuracy * 100:.2f}%')
